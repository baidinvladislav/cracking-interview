## Data Structures for Coding Interviews

<h4>Информатика на простом английском</h4>
Чтобы понять, как работают структуры данных, мы получим их с нуля, начиная с битов.

Мы рассмотрим:
* Оперативную память (RAM)
* Двоичную систему исчисления
* Целые числа фиксированной длины
* Массивы
* Строки
* Указатели
* Динамические массивы
* Связные списки
* Хэш таблицы

<h4>Оперативная память (RAM: Random Access Memory)</h4>
Когда компьютер запускает программу, ему необходимо отслеживать переменные (числа, строки, массивы и т.д.).
Переменные хранятся в оперативной памяти (RAM). Иногда мы называем оперативную память "рабочей памятью" или просто "памятью".

Оперативная память - это не то, где мы храним музыку и приложения. В дополнение к оперативной памяти, ваш компьютер
имеет хранилище (иногда его называют пстоянное хранилище или жесткий диск). В то время как оперативная память - это
то место, где мы храним переменные, которые используются в нашем коде, когда он запущен, хранилище - это то место, где
храним такие файлы, как mp3, видео, документы Word и даже исполняемые программы и приложения.

Оперативная память быстрее, но имеет меньший объем, хранилище (или диск) медленее, но имеет бОльший объем. 
Современные ноутбуки имеют 500 гб хранилища и только 16 гб оперативной памяти.

Представьте оперативную память, как большой высокий шкаф с большим количеством полок. Допустим миллиард полок.
Каждая полка пронумерована, мы называем этот номер адресом полки. На каждой полке хранятся 8 битов.
Бит - это крошечный электрический переключатель, который может быть "включен" или "выключен".
Но вместо того, чтобы говорить о них, как "включен" или "выключен", мы говорим 1 или 0 соответственно.

8 битов называются байтом, так что каждая полка в нашем шкафу храниит только один байт (8 битов).
Также нам нужен процессор, который будет выполнять всю работу внутри нашего компьютера.

Процессор подключен к котроллеру оперативной памяти. Контроллер оперативной памяти выполняет операции чтения и записи
из оперативной памяти. Контроллер оперативной памяти имеет прямое подключение к каждой полке нашей оперативной памяти (шкафа).

Прямое подключение очень важно. Это дает возможность получать доступ к разным полкам в рандомном порядке, например 
сначала мы можем получить доступ к полке с адресом 0, затем к 912712, именно из-за рандомного доступа к полкам (ячейкам) 
операционная память называется RAM (Random Access Memory). Мы можем получать доступ к случайной полке (ячейки) из любого места 
оперативной памяти.

Жесткие диски не имеют возможности рандомного доступа к хранимым элементам, потому что у них нет прямого подключения 
к каждому байту на диске. Вместо этого у них есть считывающее устройство, называемое головкой (head), 
которая перемещается по поверхности вращающегося диска хранения (как игла на проигрывателе). Чтение байтов, которые
находятся далеко друг от друга, займет больше времени, поточу что придется ждать, когда головка (head) переместится по диску.

Несмотря на то, что контроллер оперативной памяти может быстро переключаться между удаленными адресами памяти, программы, 
как правило, обращаются к памяти, расположенной поблизости.

Таким образом, компьютеры настроены на получение дополнительного прироста скорости при чтении адресов памяти, 
близких друг к другу. Вот как это работает:

Процессор имеет кэш где он хранит копии полок (ячеек), которые недавно были прочтены из оперативной памяти.
Чтение из такого кэша быстрее чем чтение из оперативной памяти, процессор экономит время когда он читает из кэша, вместо
чтения из оперативной памяти.

Когда процессор запрашивает контент из оперативной памяти по его адресу, контроллер оперативной памяти также отправляет
контент нескольких ближайщих ячеек (адресов). И процессор сохраняет это все в кэш.

Так, если процессор запрашивает содержимое адреса 951, зтем 952, затем 953, затем 954 ...
он будет отправлен оперативную память один раз (для 951), а последующие чтения будут выполняться из кэша, так как мы уже получили
эти ячейки, когда запрашивали 951.

Но если процессор запрашивает 951ую ячейку, затем 324, затем 419, то тогда кэш нам не поможет
и при каждом чтении придется полностью перемещаться между ячейками в оперативной памяти.

Таким образом чтение из последовательных адресов в памяти быстрее чем прыгать от ячейки к ячейке.

<h4>Двоичные числа</h4>
Давайте использовать эти биты. Давайте сохраним что либо, давайте начнем с цифр.
Система чисел, которую мы обычно используем (которую также преподают в школах) называется десятчной (base 10),
так как каждая цифра имеет одно из 10 возможных значений (1, 2, 3, 4, 5, 6, 7, 8, 9, и 0).
Но у компьютеров нет 10 цифр, у них есть биты в двумя возможными значениями, поэтому компьютеры используют 
двоичную систему чисел (base 2).

Десятичная система называется decimal, двоичная же называется binary.

Чтобы понять бинарную систему чисел, давайте разберемся как работает десятичная система чисел.
Возьмем для примера число 101 в десятичной системе исчисления.

Заметьте, что мы имеем две единицы в этом числе, но они не значат одно и тоже. Левая единица означает 100, и правая значит 1.
Это потому что левая единица на позиции сотен, в то время как правая единица на позиции единиц. Также ноль между единицами
находится на позиции десяток.

В итоге число 101 в десятичной системе говорит нам, что у нас 1 сотня 0 десятков и 1 единица.

Заметьте, что позиции (позиции единиц, позиции десятков, позиции сотен) в десятичной системе являются последовательными степенями числа 10:
* 10^0 = 1 
* 10^1 = 10 
* 10^2 = 100
* 10^3 = 1000
* etc

В свою очередь позиции в двоичной системе (base 2) являются последовательными степенями числа 2:
* 2^0 = 1 
* 2^1 = 2 
* 2^2 = 4
* 2^3 = 8
* etc

Рассмотри тоже самое число 101, но теперь в двоичной системе исчисления:
читаем справа налево: у нас есть единица на первой позиции, ноль позиции двоек и единица на позиции четверок. 
В итоге мы имеем: 4 + 0 + 1, что дает нам 5.

Вот как можно посчитать до 12 в двоичной системе:

| Decimal | Binary |
|---------|--------|
| 0       | 0000   |
| 1       | 0001   |
| 2       | 0010   |
| 3       | 0011   |
| 4       | 0100   |
| 5       | 0101   |
| 6       | 0110   |
| 7       | 0111   |
| 8       | 1000   |
| 9       | 1001   |
| 10      | 1010   |
| 11      | 1011   |
| 12      | 1100   |

До сих пор мы говорили о целых (не дроби) числах без знака (неотрицательные).
Хотя хранить и другие числа несложно. Вот как мы можем их представить.

* Дроби: храните два числа: числитель и знаменатель.
* Десятичные числа: также два числа: 1) число до запятой 2) число после запятой
* Отрицательные числа: зарезервируйте крайний левый бит для выражения знака числа. 0 для положительного и 1 для отрицательного.

На самом деле в реальной жизни мы будем использовать более сложные способы, но и эти подходы работают, 
а также дают нам понимание, как мы можем выражать некоторые сложные вещи, используя, только нули и единицы.

Мы обсудили десятичную и двоичную систему, вы также может быть слышали об еще одной системе,
она называется шестнадцатиричная (hexadecimal or hex). В такой системе каждое число имеет 16 возможных вариантов:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, a, b, c, d, e, и f. Такие числа часто стоят после префиков  "0x" или "#".

В CSS цвета иногда выражаются в шестнадцатеричном формате. Например, синий — «#5bc0de».

<h4>Числа фиксированной ширины</h4>
Сколько чисел мы можем выразить в одном байте (8 бите)?
2^8 = 256 различных чисел
Почему? 

Начнем с простого, сколько чисел мы можем представить в одном бите?
Только два - 0 и 1

А сколько мы можем хранить в двух битах?
Для каждой возможности из предыдущего примера мы можем добавить 0 либо до числа либо после него, 
в итоге имеем: 0, 00, 01, 1, 10, 11. Таким образов, добавив только один бит мы в два раза увеличили количетсво чисел,
было 2, добавили один бит, уже можем представить 4 числа.

Такая же идея и с 3 битами, для каждого числа из примера с 4 числами, мы добавляем 0 или 1 к каждому числу
либо до него, либо после него. Это опять нам дает увеличение чисел в два раза, было 4 числа, стало 8.

Мы можем продолжить увеличивать на один бит, получая, новое количество возможностей, но максимальное количество чисел,
которые можно расположить в 1 байте (8 битов) - это 256 различных чисел.

Что произойдет, если у нас число 255, представленное в 8 битах, как двоичное число 11111111, и добавим к нему еще 1, 
нам понадобится 9ый бит, для того что получить результат - 1000000000, но у нас только 8 битов!

Такая ситуация называется Integer Overflow. В лучшем случае мы получим ошибку, в худшем наш компьютер может вычислить
верное значение, но затем выбросить 9ый бит, дав нам 0000 0000 вместо 1 000 000 000 (256).
Python заметив, что результат не умещается в автоматически выделяет больше битов, для хранения бОльшего числа.

256 возможностей представить числа, довольно немного, поэтому мы обычно используем по 4 или 8 байтов (32 или 64 бита).

32 битные числа имееют 2^32 возможных значений, это более 4 миллиардов
64 битные числа имеют 2^64 возможных значений, это более 10 триллионов триллионов (10^19).

Замечали ли вы как в некоторых языках программирования числа представлены разными типами данных, например,
в Java и C числа могут объектами Integers, а иногда Longs. Разница заключается в количестве выделяемых для числа бит.
В Java Integers имеют 32 бита, а Longs 64 бита.

Также при создании таблиц в SQL, мы указываем кол-во байтов для чисел:
1 байт - tinyint
2 байта - smallint 
3 байта - int
4 байта - bigint

Большинство чисел имеют фиксированную длину и ширину, что означает, что количество битов, выделенных под них неизменно.
Обычно можно с полной уверенностью предположить, что число имеет фиксированную ширину, если вам не указано иное.
Существуют числа переменного размера, но они используются только в особых случаях.

Если у нас есть 64 бита, выделенных под число, то не важно какое там число будет храниться будет ли это
0 или 193.457, это в любом случае будет занимать 64 бита в оперативной памяти.

В большой О нотации числа с фиксированной шириной занимают постоянное пространство О(1).
И потому как они занимают константу, то простые операции над ними, такие как сложение, вычитание, умножение, деление,
занимают константное время О(1).

Так что фиксированные числа очень эффективны по затратам памяти, а также очень хорошо во временной сложности.

Но за эту эффективность мы платим тем, что числа ограничены, они не могут превышать 2^n возможностей, 
где n, это количество выделнных битов.

Обычно все структуры данных преследуют компромисс, чтобы получить какое то хорошее свойство,
нам часто приходится, что то терять.

<h4>Массивы</h4>
Мы рассмотрели как хранить одиночные числа, теперь рассмотрим как можно хранить несколько чисел.
Предположим, что мы хотим хранить количество выпитой нами воды за день. Давайте хранить количество литров за день в 8 битах,
с фиксированной шириной, беззнаковое целое число. Этого места должно быть достаточно, ведь мы не сможем выпить за день более
256 (2^8) литров. Давайте хранить данные по дням рядом друг с другом прямо в оперативной памяти,
начиная с адреса 0. Мы можем заметить сходства оперативной памяти с массивами в языках программирования,
на самом деле RAM - это и есть массив. В массивах, также как и в RAM элементы пронумированы. Мы можем называть это номер
индекс элемента в массиве. Иногда каждый адрес элемента в массиве совпадает с адресом элемента в оперативной памяти.
Но это не всегда так. Предположим, какая то программа, например, Spotify уже зарезервировала памяти для информации под адресом 2.
Мы должны начать массив, начиная с этого элемента, например, с адреса 3. Таким образом индекс 0 в нашем массиве будет
иметь адрес 3 в RAM, а индекс 1 в массиве будет иметь адрес 4 в RAM.

Допустим, мы хотим получить количество выпитых нами литров из нашего примера выше под индексом 4 в нашем массиве.
Как нам вычислить адрес этого элемента в RAM? Простая математика:
Возьмем начальный адресс массива (3), добавим индекс, который мы ищем (4), и это будет нашим адресом в оперативной памяти.
Вообщем, для получения n-го элемента в массиве формула такая:

адрес для n-го в массиве = адрес начального элемента массива + n.

Это работает хорошо, потому что размер адресуемых слотов памяти и размер количество выпитых литров равны одному байту.
Но это не всегда так. Обычно это не так. Обычно мы используем 64-битные числа.

Так как же нам построить массив 64-битных (8 байтовых) целых чисел поверх наших 8-битных (1-байтовых)
слотов памяти?

Мы можем дать каждому элементу в массиве 8 адресов вместо 1 (вложить массивы в массив).
Мы по пренему используем математику для получения n-го элемента массива, просто добавим умножение.


адрес для n-го в массиве = адрес начального элемента массива + (n * размер каждого элемента в байтах).

Данное умножение не сильно замедлит производительности нашей работы, потому что как мы помним массивы имеет константную
временную сложность для операций: сложения, вычитания, умножения, деления. Так что вся формула будет работать за О(1).

А также помним о том, что контроллер памяти имеет доступ к любому адресу за О(1).
Все вместе означает, что поиск заданного индекса в массиве производится за О(1).
Свойство быстрого доступа в элементу самое важное свойство у массивов.

Но формула, которую мы использовали для получения адреса n-го элемента в массива работает, только если:
1. Каждый элемент в массиве одного размера (занимает одно каличество байтов)
2. Массив непрерывен в памяти. В нем не может быть каких либо пробелов, например, пропуск слота, 
который уже зарезервирован программой. 

Эти свойства делают нашу формулу для поиска n-го элемента рабочей, потому что они делают наш
массив предсказуемым. Мы может предсказать где точно в памяти n-ый элмент находится в массиве.

Но также они накладывают ограничение какие элементы мы можем хранить в массиве, каждый элемент должен быть одного размера.
А также, если наш массив будет содержать большое кол-во элементов, то нам понадобится большое количество непрерывного места 
для такого массива. Это может быть сложно задачей, если большая часть нашей оперативной зарезервирована другими программами.

Это компромисс. Массивы имеют быстрый доступ за О(1), но каждый элемент в массиве должен быть одного размера, а также 
нам нужен будет блок неприрывной памяти в RAM, чтобы хранить массив.


<h4>Строки</h4>
Рассмотрим, как мы можем хранить слова. Серия символов (буквы, пунктация и т.д.) называются строкой.
Мы уже знаем как мы можем хранить серии чего либо - в массиве. Но как массив может хранить символы вместо чисел?

Предположим, что у нас есть маппинг между числами и символами. Например, А это 1 (0000 0001 в бинарной системе),
В это 2 (или 0000 0010 в бинарной системе). Теперь у нас есть и символы.

Такое сапоставление символов с числами называется кодировкой символов. Одна из распространенных символьных кодировок ASCII.
Таким образом, поскольку мы можем представить символы как 8 битовые числа, мы можем представить строки как массивы 8 битных символов.


<h4>Указатели</h4>
Как уже было сказано, каждый элемент в массиве должен быть одного размера с другими. Рассмотрим это подробнее.
Допустим мы хотим хранить список имен. Каждое имя - это строка. Строка на самом деле является массивом.
И как мы можем хранить массивы в массиве?

Ведь, что если массивы будут разной длины, ведь имена так могут делать. Мы можем записывать в массив массивы большой длины, 
скажем 13 символом и помечать 14ым элементов *, что будет означать конец имени, и так после каждого имени ...

Но так будет много потерянного места. Есть способ лучше. Вместо того, чтобы хранить строки прямо в нашем массиве,
мы можем хранить элементы в любом месте оперативной памяти, тогда каждый элемент в нашем массиве будет хранить адрес необходимого
нам элемента в другом месте памяти.

Каждый адрес представляет собой целое число, так что на самом деле наш внешний массив — это просто массив целых чисел. 
Каждое из этих целых чисел можно назвать указателем, поскольку оно указывает на другое место в памяти.

Это избавляет нас от двух главных недостатков массивов:
1. Элементы необязательно должны быть одной длины.
2. Нам больше не нужно неприрывное место в памяти для хранения массива.

Мы убрали все компромиссы в массивах? На самом деле нет. Помните, как контроллер памяти отправляет контент соседних ячеек в памяти
процессору? А процессор кэширует их? Таким образом последовательные адреса в памяти давали нам рост производительности,
потому что мы могли брать, запрашиваемые данные из кэша?

Наш исходный массив был очень удобным для кэширования, потому что все было последовательно. 
Таким образом, чтение с 0-го индекса, затем 1-го индекса, затем 2-го и т. д. получило дополнительное ускорение 
за счет кеша процессора.

Но указатели в нашем массиве не кэш-френдли, потому что имена разрбросаны по всей оперативной памяти.
Так что чтение 0 индекса, затем 1, затем 2 и так далее не будет давать прирост в производительности работы процессора
за счет кэша.

Это тоже является компромиссом. Массив на сонове указателем требует меньше непрерывно расположенной памяти в RAM,
а также может позволить не соблюдать элементам массива один размер, но будет работать медленне, потому что это не кэш-френдли.

Стоит отметить, что уменьшение по производительности за счет использование указателей, не влияет на большое О, 
доступ элемента по индексу из массива по прежнему работает за О(1).


<h4>Динамические массивы</h4>
Давайте создадим очень простой текстовый процессор. Какую структуру данных нам следует использовать для этой цели?
Строки хранятся в массиве, значит нам стоит использывать именно его?

Здесь есть проблема, дело в том, что в низкоуровневых языках, например, таких как С, мы должны заранее указать размер
создаваемого массива. Это происходит из-за того компьютер должен зарезрвировать место в памяти для массива.
Мы не можем позволить другой программе переписывать элементы нашего массива. Компьютер не может зарезрверивать всю память
одним массивом, ему нужно знать сколько конкретно памяти следует зарезервировать. Но наш текстовый процессор не может не заранее
знать насколько большой документ будет у пользователя.

Мы можем создать массив и програмно увеличивать его размер каждый раз, когда ему не хватает места, это называется
динамический массив, он создается поверх обычного массива.

Python, Ruby, JavaScript используют динамические массивы, как стандартные массиво-подобные структуры данных.
В Python они называются списки. В других языках есть как статичные так и динамические массивы, например в Java 
static чей массив неизменяется, а также есть ArrayList что является динамическим массивом.

Рассмотрим как это работает.

Когда вы выделяете динамический массив, ваша реализация динамического массива создает базовый статический массив.
Начальный размер зависит от реализации, допустим наша использует 10 индексов.

Теперь мы добавим 4 элемента в наш динамический массив. Теперь у нас 4 элемента в массиве. Он имеет длину 4, 
но базовый массив имеет длину 10. Мы можем сказать, что наш массив имеет размер (size) 4 вместимость (capacity) 10.

Динамический массив хранит индекс последнего элемента, где динамический массив заканчивается, а дополнительная память начинается.
Если мы продолжим добавлять элементы в наш изначальный массив, то мы используем всю его память, займем все 10 индексов.
Когда память массива исрасходована под капотом происходит следующее:

1. Сделать новый массив бОльшего размера. Обычно в два раза больше.
Почему бы нам просто не расширить текущий? Потому что память может быть уже занята.
Допустим, у нас открыт Spotify, и он использует несколько адресов памяти сразу после последнего элемента нашего старого массива.
Нам придется пропустить эту память и зарезервировать следующие 20 непрерывных слотов памяти для нашего нового массива.
2. Скопировать каждый элемент старого массива в новый массив.
3. Высвободить память старого массива. Мы даем понять ОС, что теперь она может использовать память старого массива для 
чего нибудь другого.
4. Добавьте свой новый элемент.

Мы могли бы назвать такие добавления "дублирующими" добавлениями, посколько они требуют от нас создания нового массива,
который (обычно) удваивает размер старого массива.

Добавление элемента в массив обычно занимает О(1) времени, но одно "дублирущие" добавление требует О(n) времени,
посколько мы должны скопировать каждый элемент в наш новый массив из старого.

Значит ли это, что каждая операция добавления в массив всешда занимает О(n) в худшем случае?

В то время дублирующие добавление увеличивает массив в два раза каждый раз, количество добавления за О(1) также увеличивается в два раза.
Мы можем сказать, что каждое добавление в массив имеет амортизированную сложность О(1).

Как правило инженеры допускают говорить сложность вставки в массив стоит нам О(1), хотя, строго говоря, это врено только
для среднего случая или для амортизированной стоимости.

На интервью, если мы беспокоимся о O(n) в худшем случае при добавлении в массив, мы можем использовать обычный не динамический массив.

Преимущество динамического массива в том, что нам не нужно указывать его точный размер при инициализации, но его недостакток
в том, что некоторые вставки могут быть дорогими. Это его компромисс.


<h4>Связные списки</h4>
Наш текстовый процессор определенно должен иметь возможность быстрой вставки. Добавление в документ, это основная вещь,
которую делает текстовый процессор. 

Можем ли мы построить такую структуру данных, которая может хранить строку, иметь быструю вставку и
не требывать информации о том насколько длинная строка может быть?

Давайте сосредоточимся для начала, на том чтобы не указывавть структуре данных заранее насколько длинной может быть строка.
Помните, как мы обходили ограничения массива с длиной в массиве имен?

Что если мы пойдем дальше? 
Что если каждый символ нашей строки будет массивом из двух индексов?
1. Сам символ строки
2. Указатель на следующий символ строки

Мы можем назвать каждый такой массив - узлом (node), а также мы можем назвать последовательность таких узлом связным списком.
Такие узлы могут храниться не рядом друг с другом в памяти.

Первый узел связного списка называется голова (head), а последний узел связного списка называется хвост (tail).
Важно иметь указатель на начало списка, иначе мы не сможем вернуться к началу списка.

Также иногда мы будем отслеживать указатель на хвост. Это очень удобно, когда мы должны добавить новый элемент в конец списка.

Например, у нас есть последовательность узлов: L -> O -> G.
Допустим, мы хотим добавить "S" в конец нашего списка, как нам это сделать?

1. Найдем последний символ в списке, это "G", наше указалель на хвост сделает это для нас за О(1).
2. Указатель следующего символа узла "G" изменить на узел "S".
3. Обновить укзатель на хвост, переместив его на наш новый последний символ "S".

Это все работает за О(1). Почему? Потому что скорость работы алгоритма не стане больше, если строка станет больше.
Не важно как много символов в строке, мы все равно нужно переставить пару указателей для добавления нового элемента.

Теперь, что если вместо связного списка, наша строка бы была добавлена в динамический массив?
У нас может не хватить места в конце, что заставит нас выполнить операцию удвоение массива.

Таким образом в динамическом массиве, наше добавление будет в хедшем случае за О(n).

Связной список имеет худший случай для вставки О(1), что лучше чем худший случай O(n) в динамическом массиве.

Худший случай здесь очень важен, потому что средний случай для добавления и в связной список, и в динамический массив - 
одинаков, это будет O(1).

Теперь рассмотрим добавление в начало связного списка. Допустим мы хотим добавить узел "B" в начало списка L -> O -> G -> S.
В нашем связном списке это будет также легко:

1. Указатель узла "B" переставить на узел "L".
2. Обновить укзатель на голову связного списка на узел "B".

Вставка в начало связного списка также за О(1).

Что бы поменялось, если бы наш список был представлен динамическим массивом?
Наш массив: [L, O, G, S] и нам нужно добавить "B" в начало массива.

Для этого нам нужно освободить место в начале, для этого мы двигаем каждый элемент динамического массива на одну позицию вправо (в конец).
И только теперь мы сможем добавить "B" в начало, в пустую ячейку динамического массива.

На шаге, где мы смещаем каждый символ в новый индекс, мы затрачиваем O(n).

Так что, связные списки имеют более быструю вставку в начало списка О(1), чем динамический массив О(n).
Теперь нет никаких оговорок, добавление в конец массива занимает O(n) в среднем, не в худшем случай, если сравнивать с добавлением в конец.

Быстрые добавление в конец и начало связного списка реализовано за счет того, что элементы списка могут находиться в любом месте в памяти.

Они не должны находиться рядом, как это делают элементы в массиве.

Если связные списки так хороши, почему же мы обычно храним строки в массивах? Потому что массивы имеют доступ к элементу за O(1)
и это время также приходит из-за того элементы массива находятся рядом друг с другом в памяти.

Доступ к элементу в связном списке сложнее, потому что мы не можем знать где находится узел в памяти.
Так что нам нужно будет пройти весь список по очереди, пока мы не найдем искомый элемент.

Таким образом доступ к элементу в связном списке реализован за O(n), что гораздо медленне чем в массиве за O(1).
Также просмотр связанного списка не удобен для кэширования. Поскольку следующий узел может находиться где угодно в памяти, 
мы не получаем никакой выгоды от кэша процессора. Это означает, что поиск в связанном списке выполняется еще медленнее.

Преимущества связного списка заключаются в быстрых вставке в начало и конец списка, 
но доступ к элементу намного быстрее у массива. 

<h4>Хэш таблицы</h4>
Быстрый доступ к элементу часто очень важен. Поэтому мы чаще используем массив с О(1) за доступ к элементу,
вместо связного списка с его О(n). Например, нам нужно подсчитать сколько раз встрается каждый символ ASCII в романе "Ромэо и Джульетта",
как нам следует хранить эти подсчеты?

Мы можем использовать для этого массив, не самым очевидным способом. Помните, что каждый символ - это на самом деле цифры.
В ASCII 'A' - 65, 'B' - 66. Таким образом, мы можем использовать цифровое значение символов как индекс в массиве, и хранить число
повторов для каждого символа. Используя, таким образом массив, мы можем получать число повторов для каждого символа по его индексу
за О(1).

Кое что интересное происходит здесь - данный массив не просто список значений. Теперь он хранит две вещи:
символы и повторы символов в книге. Символы подразумеваются индексы.

Так что мы можем представить массив, как таблицу с двумя столбцами: индексы и значения.
Значения в столбце индексы не могут быть выбраны, они всегда будут иметь вид: 0, 1, 2, 3 ...

Но что если мы все таки хотим так делать? Перевести символ в число не было сложно, но как нам сделать тоже же самое со всем словом?

Мы можем взять числовое значения для каждого символа и сложить их, например:
 l i e s = 108 + 105 + 101 + 115 = 429

Получаем 429, но что если у нас нет столько слотов, у нас есть только 30? 
Тогда мы можем использовать обычный прием для помещения числа диапазон: оператор модуля (%).
Изменение нашей суммы на 30 гарантирует, что мы получим целое число меньше 30 (и не менее 0):
429 % 30 = 9

Теперь мы получили индекс для всего слова.

Подобная структура данных называется "хэш таблица" (hash table/hash map). В нашей хэш таблице, счетчики повторов слов значения,
а слова ключи (аналогично как с индексами в массиве). Процесс, 
который мы использовали для преобразования ключа в индекс массива, называется функцией хеширования. 
Современные функции хэширования гораздо сложнее устроены, это базовый пример. Обратите внимание, на то что у нас односторонний
поиск, мы можем получить значение для любого ключа, но единственный способ получить ключ по значению, это перебрать все пары
в хэш таблице. Точно также как и в массиве, мы можем быстро получить значение по индексу, но единственный способ определить 
индекс для конкретного значения - это пройстись по всему массиву. 

Есть проблема - что если два ключа были после хэширования дали один и тот же результат?
Например, "lies" и "foes":
l i e s (108 + 105 + 101 + 115) + f o e s (102 + 111 + 101 + 115) = 429

Мы получили одинаковую сумму для обоих слов и конечно же получим одинаковый индекс для обоих слов:
429 % 30 = 9

Когда два элемента хэш таблицы преобразуются в одинаковый хэш, такое явление называется хэш колизией (hash collision).
Есть несколько способов борьбы с ней.

Рассмотрим первый: вместо того, чтобы хранить значения счетчиков сразу в массиве, давайте хранить под ключом с колизией 
связной список, где будут содержаться все счетчики для ключа с коллизией.

Проблема - как нам понять, какой счетчик принадлежит какому слову?
Мы можем хранить на каждом узле списка еще и слово, проходить по списку и выбирать тот узел, который нам необходим.

Но тогда мы будем уходить от константной сложности доступа к элементу к линейной, также правда и то, что худший случай доступа
к элементу хэш таблицы O(n), это произойдет в случае, если каждый ключ является ключом с коллизией, тогда наша хэш таблица 
превратится в связной список.

Однако в промышленности коллизии довольно редкое явление и поэтому в среднем доступ к элементу в хэш таблицу занимает 
меньшее время и работает за О(1). 

У хэш таблицы тоже есть свои компромиссы. У них есть быстрый доступ к элементу массива, хотя некоторые доступы могут быть медленее
(из-за коллизий), а также у нас есть быстрый доступ к элементу, но не к ключу, так что перебор таблицы для поиска ключа по значению
займет O(n) времени.

<h4>Вывод</h4>
Массивы имеют доступ к элементу за О(1). Но нам нужно иметь достаточно непрерывного пространства в оперативной памяти,
чтобы хранить весь массив рядом. Также элементы должны быть одного размера, чтобы была возможность зарезервировать память 
под массив, нужно знать сколько конкретно ячеек резервировать.

Но если в вашем массиве хранятся указатели на фактические элементы массива (как мы делали со списком имен),
то мы можем обойти оба этих недостатка (требование непрерывной памяти/знание размера массива заранее).
Мы сможем хранить каждый элемент в любом месте нашей оперативной памяти, а также наш элемент сможет хранить элементы
разного размера. Минус такого подхода в том, что теперь массив работает меньше, потому что он становится менее удобен для
кэширования, теперь элементы хранятся в разных местах.

Другая проблема в том, что массиву нужно указать его размер заранее, есть два решения этой проблемы: 
динамический массив и связной список. Связные списки быстрее для вставки в начало и в конец списка, а динамические массивы
имеет более быстрый доступ к элементу.

Быстрый доступ к элементу очень важен, особенно если мы ищем не просто по индексу, как в массиве (0, 1, 2, 3 и так далее), 
а, например, по ключам, например, по какому то слову. Это то что называется хэш-таблицей. Единственная проблема с хэш таблицами
это хэш коллизии, которые делают некоторые доступы к элементу таблице медленее.

Каждая структура данных имеет свои плюсы и минусы, не бывает идеальных структур.
