## Big O Notation
<h4>Значение большого О</h4>

Большое О - это "язык", который используется для определения того как долго работает алгоритм.

При помощи натации большого О мы можем выразить как быстро растет сложность алгоритма по мере роста входных данных.

1. Сложно сказать сколько точно займет выполнение какого либо алгоритма, потому что 
это зависит от скорости процессора, от его загрузки и т.д. Поэтому вместо того, чтобы говорить о времени выполнения конкретно
мы используем измереяем сложность в большой О нотации, чтобы определить насколько быстро растет сложность алгоритма.
2. Если бы измеряли скорость выполнения алгоритма, то мы измеряли время в секундах, но так как мы измеряем как быстро растет сложность,
то нам необходима другая единица изменерения. В большой О нотации мы используем размер входных данных для этого, мы можем
сказать, что сложность алгоритма растет линейно с увеличением входных данных или можем сказать, что сложность алгоритма
растет квадратично по мере роста входных данных.
3. Наш алгоритм может иметь шаги, которые кажутся довольно "дешевыми" на маленьких входных данных, но 
те же самые шаги могут быть очень дороги по мере роста входных данных.


<h2>Рассмотрим примеры</h2>

```python
def print_first_item(items):
    print(items[0])

```
  

<b>Эта ф-ия имеет константную или О(1) сложность</b>. Входящий массив может содержать 1 элемент, а может и 1000 элементов,
но ф-ия всегда будет требовать один шаг.

```python
def print_all_items(items):
    for item in items:
        print(item)

```

<b>Эта ф-ия имеет линейную или O(n) сложность, где n это количество элементов с списке.</b> Если список сотоит из 10 элементов, 
мы вызовем ф-ию print 10 раз. Если в списке 1.000 элементов, мы вызовем ф-ию print 1.000 раз.

```python
def print_all_possible_ordered_pairs(items):
    for first_item in items:
        for second_item in items:
            print(first_item, second_item)

```

<b>В этом примере у нас вложенный цикл в цикл. Если в списке n элементов, наш внешний цикл сделает n итераций, а также наш внутренний цикл сделает n итерации,
что в итоге нам даст квадратичное или O(n^2) сложность алгоритма.</b>. 
Если в списке 10 жлементов, мы вызовем ф-ию print 100 раз. Если у нас в списке 1.000 элементов, мы вызовем print 1.000.000 раз.


<h2>N может быть самим инпутом, а может быть размером инпута</h2>

Обе эти функции имеют сложность O(n), даже несмотря на то что одна принимает число, а вторая список:

```python
def say_hi_n_times(n):
    for time in range(n):
        print("hi")


def print_all_items(items):
    for item in items:
        print(item)

```

Так иногда n это число переданное в функции, а иногда коллекция элементов.

<h2>Константами можно принебречь</h2>

Когда мы говорим об большой О мы можем отбрасывать константы:

```python
def print_all_items_twice(items):
    for item in items:
        print(item)
    
    # Once more, with feeling
    for item in items:
        print(item)

```

Эта функция имеет O(2n) сложность, мы можем просто сказать O(n).

```python
def print_first_item_then_first_half_then_say_hi_100_times(items):
    print(items[0])
    
    middle_index = len(items) // 2
    index = 0
    
    while index < middle_index:
        print(items[index])
        index += 1
    
    for time in range(100):
        print("hi")

```

В этом примере ф-ия работает за O(1 + n/2 + 100), но мы по прежнему получаем O(n) без констант.

Почему мы можем отбросить константы? Так как большая О представляет сложность, когда алгоритм работает с большими входящими данными, 
то увеличение сложности на константу раз (2 или 100 в примере выше) не настолько значительно, что может быть отброшено.

<h2>Отбрасываем меньшую сложность</h2>

```python
def print_all_numbers_then_all_pair_sums(numbers):
  print("these are the numbers:")
  for number in numbers:
      print(number)

  print("and these are their sums:")
  for first_number in numbers:
      for second_number in numbers:
          print(first_number + second_number)

```


Сложность ф-ии O(n + n^2), но мы можем просто сказать O(n^2). Даже, если сложность будет O(n^2 / 2 + 100n),
все равно алгоритм будет работать за O(n^2).

Точно также:
O(n^3 + 50n^2 + 1000) это все еще O(n^3)
O(n + 30) * (n + 5) это все еще O(n^2)

Мы можем себе позволить отбросить менее значимую сложность, потому что по мере роста входных данных, 
меньшая сложность будет наименее заметна.


<h2>Обычно мы подразумиваем "худший случай"</h2>

Обычно под сложностью подразумивается "худший случай", но можно и уточнить прямо у интервьюера.

Иногда худший случай значительно хуже, чем лучший случай:

```python
def contains(haystack, needle):

    # Does the haystack contain the needle?
    for item in haystack:
        if item == needle:
            return True
    
    return False

```

В данном случае мы можем иметь список из 100 элементов, но если первый элемент, окажется, тем что мы ищем, 
в этом случае мы вернем результат всего за одну итерацию.

В таком случае мы скажем, что сложность будет O(n) и мы будем иметь ввиду "худший случай". 
Более точно мы можем сказать, что сложность этой ф-ии равна O(n) и лучший случай равен O(1). 
В некоторых алгоритмах также стоит обращать внимание и на "средний случай" исполнения алгоритма.

<h2>Пространственная сложность</h2>


Иногда нам необходимо оптимизировать работу алгоритма, за счет снижения временной или пространственной сложности. 
Пространственная сложность напоминает временную сложность. 
Мы смотрим на итоговый размер (зависищих от инпута) переменных, которые мы инициализировали.

Эта ф-ия имеет O(1) пространственную сложность (мы не инициализируем дополнительных переменных):

```python
def say_hi_n_times(n):
    for time in range(n):
        print("hi")

```

Эта ф-ия имеет O(n) пространственную сложность (размер hi_list растет по мере роста нашего инпута):

```python
def list_of_hi_n_times(n):
    hi_list = []
    for time in range(n):
        hi_list.append("hi")
    return hi_list

```
<b>Обычно говоря о пространственной сложности, мы говорим о дополнительной памяти</b>, так что мы не включаем память занятую инпутом. 
Например, эта ф-ия имеет константную пространственную сложность, хотя инпут имеет n элементов:

```python
def get_largest_item(items):
    largest = float('-inf')
    for item in items:
        if item > largest:
            largest = item
    return largest

```

<b>Существует компромисс между затратами по времени и по памяти</b>, 
так что нам нужно будет решить, что мы хотим за счет чего оптимизировать.


<h2>Опитимизация значений большого О - это замечательно, но есть и подводные камни</h2>

Следует выработать привычку задумываться о временной и пространственной сложности алгоритмов, которые вы реализуете. 
Вскоре это станет второй натурой, позволяя вам видеть возможные оптимизации и потенциальные проблемы с производительностью.
Асимптомический анализ - это прекрасно, но используйте это с умом. Большое О игнорирует константы, но <b>иногда константы важны</b>. 
Если нашему скрипту нужно 5 часов на исполнение, оптимизация, которая снизит время выполнения скрипта в 5 раз может не повлиять на временную сложность большого O, 
но это по прежнему сэкономит вам 4 часа ожидания исполнения скрипта.

<b>Избегайте преждевременную оптимизацию.</b>Иногда оптимизация времени и памяти может негатиавно влиять на читаемость
и требует больше временных затрат от разработчика. Для молодых стартапов может быть важным писать код, 
который разработчики могут быстро создать, а также, который легко читается, 
даже если такой код потребует бОльшие затраты по временной и простанственной сложности.
Но это также не означает, что стартапы не заинтересованы в асимпотитеском анализе. 
Не важно в каком месте работать, хороший инженер должен знать, как соблюсти правильный баланс между 
врменной сложностью, пространственной сложностью, временем на реализацию, поддерживаемости, а также читаемости.
<b>Тебе нужно освоить навык видеть возможные оптимизации по временной и пространственной сложности, 
а также приобрести мудрость, чтобы понимать стоит ли применять данные оптимизации в своем алгоритме.</b>
