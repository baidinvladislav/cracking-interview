Рассмотрим ситуацию, мы написали парсер, который свободно посещает сайты в сети интернет.
Для того чтобы парсер не посещал один и тот же сайт дважды, мы выделили множество для хранения посещенных сайтов.
Через какое то время множество сайтов стало слишком велико, как оптимизировать затраты по памяти?

Оптимизация не должна навредить скорости работы.

Рассмотрим множество сайтов, каждый сайт наичнается 'www'.
Мы можем реализовать множество сайтов, как вложенный словарь, где внешний ключ - это поддомен, внутренний ключ - это
остальная часть URL. Например, visited['www.']['google.com'] = True и visited['www.']['interviewcake.com'] = True.

Теперь вместо сохранения «www.» для каждого из этих URL-адресов мы только что сохранили его один раз в памяти.
Если у нас хранится 1.000 адресов и половина из них начинается с «www.» тогда вместо сохранения 500x4 символов, 
мы сохраним в памяти только 4.

Но мы можем еще лучше.

Что если мы используем тот же подход выделения общего префикса рекурсивно?
Какой длины нам следует делать префиксы? Что если мы сделаем префиксы только лишь из одной буквы?

Мы можем использовать структуру данных Trie.

Представим множество посещенных сайтов, как вложенный словарь, где каждый словарь имеет только один символ.
Мы будет хранить 'google.com' как  visited['g']['o']['o']['g']['l']['e']['.']['c']['o']['m']['*'] = True
'*' в конце, значит конец URL. Иначе нам было бы сложно различать префиксы от полного сайта. В примере выше
'google.co'  - это префикс, который мы могли бы принять за посещенный URL-адрес, если бы у нас не было способа обозначить конец сайта.

Теперь, когда мы будем добавлять 'google.com/maps' в посещенные сайты, мы добавим только '/maps', потому как 'google.com'
уже находится там, тоже самое и с 'google.com/about/jobs'.

Мы можем представить это как дерево, где каждый символ в строке соответствует узлу. Три - это тип дерева.

Чтобы проверить, находится ли строка в дереве, мы просто спускаемся от корня дерева к листу, 
проверяя наличие узла в дереве, соответствующего каждому символу в строке.

Как мы можем реализовать такую структуру? Есть несколько способов.
Мы можем использовать: вложенные словари, узлы и указатели. Оценка плюсов и минусов различных вариантов 
и выбор одного из них — отличная вещь на собеседовании по программированию. 

В нашей реализации мы используем два вложенных словаря.
Чтобы определить, посещался ли данный сайт, мы просто вызываем add_word(), который добавляет слово в дерево, если его там еще нет.


```python
class Trie(object):

    def __init__(self):
        self.root_node = {}
    
    def add_word(self, word):
        current_node = self.root_node
        is_new_word = False
    
        # Work downwards through the trie, adding nodes
        # as needed, and keeping track of whether we add
        # any nodes.
        for char in word:
            if char not in current_node:
                is_new_word = True
                current_node[char] = {}
            current_node = current_node[char]
    
        # Explicitly mark the end of a word.
        # Otherwise, we might say a word is
        # present if it is a prefix of a different,
        # longer word that was added earlier.
        if "End Of Word" not in current_node:
            is_new_word = True
            current_node["End Of Word"] = {}
    
        return is_new_word

```

Также можно использовать троичное дерево поиска или фильтр Блума.

<b>Сложность</b>
Сколько символов мы хранили в нашем обычном словаре? Предположим наш словарь включает все возможные URLs длиной 5 символов и менее.
Давайте проигнорируем неалфавитные символы для упрощения, придерживаясь стандартных 26 английских букв в нижнем регистре.
Есть 26^5 5 различные возможные 5-символьные URL-адреса (26 вариантов для первого символа, 26 вариантов для второго символа т.д.),
и конечно 26^4 4 различных вариантов для 4-символьных URL-адресов. Если мы храним каждый 5-символьный URL как обычную строку
в памяти, мы храним 5 символов для каждой строки, всего 5 * 26^5 символов для всех возможных 5-символьных строк (и 4 * 26^4 общее количество символов для всех 4-символьных строк и т. д.). 
Таким образом, для всех URL-адресов из 1, 2, 3, 4 или 5 символов общее количество сохраненных символов составляет:
5 * 26^5 + 4 * 26^4 + 3 * 26^3 + 2 * 26^2 + 1 * 26^1

Таким образом, для всех возможных URL-адресов длины n или меньше наш общий объем памяти равен:
n26^n + (n - 1) * 26^n-1 + ... + 1 * 26^1
Это O(n26^n).

Сколько символов мы храним в нашей Trie структуре?
Первый слой имееет 26 узлов (и следовательно 26 символов), по одному для каждого возможного начального символа.
Во втором слое, каждый из этих 26 узлов имеет 26 дочерних, всего 26^2 узлов. Пятый слой имеет 26^5 узлов.
Чтобы хранить все 1,2,3,4,5 символьные URL адреса наше Trie будет иметь 5 слоев. Таким образом, общее количество узлов равно:
26^5 + 26^4 + 26^3 + 26^2 + 26^1

Таким образом, для всех URL-адресов длины n или меньше мы имеем:
26^n + 26^(n-1) + ... + 26^1
Это O(26^n). Мы избавились от n коэффицента.

<b>Что изучили</b>
Мы начали со стратегии сжатия общего префикса ('www') и затем спросили себя, "как мы можем применить ту же идею еще глубже?"
Это один из ключей, чтобы решать сложные алгоритмы и использовать сложные структуры данных в задачах, которые ты не встречал раньше.
