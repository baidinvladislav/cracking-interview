## Example greedy problems

<h3>Example 1: 2126. Destroying Asteroids</h3>
You are given an integer array asteroids and an integer mass representing the mass of a planet. 
The planet will collide with the asteroids one by one - you can choose the order. If the mass of the planet is less 
than the mass of an asteroid, the planet is destroyed. Otherwise, the planet gains the mass of the asteroid. 
Can you destroy all the asteroids?

We need to choose the optimal order in which the planet collides with the asteroids. Let's say that at the start, 
only two asteroids have a mass less than or equal to the planet, x and y, where x < y < planet. 
Which should we choose to collide first? The answer is that it doesn't matter. Because our mass can only increase, 
if at any point we can destroy an asteroid, we will always be able to destroy that asteroid in the future. 
What's the easiest way to figure out what asteroids we can take at any given step?

To maintain the asteroids that we can destroy, we can sort the input and iterate through it. Then, 
we can just greedily choose the asteroid with the smallest mass at each step. If at any step, 
the smallest remaining asteroid has a mass greater than our planet, then destroying all asteroids is impossible 
and no order of asteroids would allow us to continue.

Although there could be many strategies that lead to a correct solution, 
greedily choosing the smallest remaining asteroid at every step is an intuitive and easy to implement strategy.

```python
class Solution:
    def asteroidsDestroyed(self, mass: int, asteroids: List[int]) -> bool:
        asteroids.sort()
        for asteroid in asteroids:
            if asteroid > mass:
                return False
            mass += asteroid
        
        return True
```

As you can see, after realizing that greedily choosing the smallest asteroid is the optimal method, 
implementing the algorithm is very simple. This algorithm has a time complexity of O(n⋅logn) due to the sort, 
where n is the number of asteroids. The amount of space used is dependent on the language you are using. For example, 
Python implements timsort which uses up to O(n) space, but a language that uses quicksort uses O(logn) space.

<h3>Example 2: 2294. Partition Array Such That Maximum Difference Is K</h3>
Given an integer array nums and an integer k, split nums into subsequences, where each subsequences' maximum 
and minimum element is within k of each other. What is the minimum number of subsequences needed?

For example, given nums = [3, 6, 1, 2, 5] and k = 2, the answer is 2. The subsequences are [3, 1, 2] and [6, 5].

We talked about subsequences briefly in the arrays and strings chapter, but as a reminder, 
a subsequence is a group of elements from the array that keep their order. They're like subarrays, 
but the elements don't need to be adjacent.

In this problem, for each subsequence, we only care about the maximum and minimum value. 
The actual order of the elements in the subsequence doesn't matter. Without the order requirement, 
subsequence is the same as subset. We also spoke about subsets briefly, 
but a subset is just any set of elements from the array.

What is the best way to group the elements? We want to minimize the number of groups, 
so we want to maximize the number of elements in the groups. Let's say we start with the smallest number in the input x. 
We want all elements in the range [x, x + k] to be grouped. It doesn't make sense for any 
of these elements to not be in the group - let's say we decided to exclude x + k - 1. Then, 
the next group would have to start at a smaller number. This limits the range of elements that can be grouped, 
which goes against what we want.

Thus, it's best to greedily take all elements within the range [x, x + k] for the smallest number x. After that, 
we can "erase" those numbers from the array, and we have the same problem again with a different x. 
What is the best way to execute this? Sort the array and iterate over it. 
Because we logically reduced subsequences to subsets, sorting doesn't change anything.

Let's say we have nums = [3, 6, 1, 2, 5] and k = 2. The optimal subsequences are [3, 1, 2] and [6, 5]. 
What if we sort the input? Then we would have [1, 2, 3, 5, 6]. We completely messed up the order of the elements 
and the two optimal subsequences don't exist anymore.

Does it matter though? Is there any meaningful difference between [3, 1, 2] and a new subsequence 
that can be formed from the sorted input [1, 2, 3]? No, because in both, 
the only thing we are concerned about is the maximum and minimum element, which is independent of the order. 
Therefore, we can sort the input without worry.

The smallest element 1 must be in a group. We are allowed to put the 2 and 3 in the same group because they're within k. 
Should we? If we do, then we increment our answer by one, and then we have to solve the remaining problem [5, 6].

If we exclude the 3, then we need to increment our answer by one, and then we have to solve the remaining problem [3, 5, 6]. 
If we exclude both 2 and 3, then we need to increment our answer by one, 
and then we have to solve the remaining problem [2, 3, 5, 6].

In all 3 cases, we increment our answer by one. Therefore, we may as well choose the case 
where the remaining problem is the smallest since we want to minimize the answer. 
We can conclude that the optimal strategy is to greedily take as many numbers as we can per group, 
which is easy to do once we sort the input.

Note that while this isn't a formal mathematical proof for the correctness of the strategy, 
it would be a sufficient explanation in an interview.

```python
class Solution:
    def partitionArray(self, nums: List[int], k: int) -> int:
        nums.sort()
        ans = 1
        x = nums[0]
        
        for i in range(1, len(nums)):
            if nums[i] - x > k:
                x = nums[i]
                ans += 1
        
        return ans
```

To summarize: set x at the start and take as many elements as you can. Once you go beyond x + k, 
increment the answer and start again with a new x. This runs in O(n⋅logn) where n is the length 
of the input array due to the sort. Again, the only extra space used is during the sort, 
and the complexity depends on the sorting algorithm used by your language of choice.

<h3>Example 3: 502. IPO</h3>
LeetCode would like to work on some projects to increase its capital before IPO. You are given n projects 
where the i-th project has a profit of profits[i] and a minimum capital of capital[i] is needed to start it. 
Initially, you have w capital. When you finish a project, the profit will be added to your total capital. 
Return the max capital possible if you are allowed to do up to k projects.

We can choose up to k projects. Which ones should we choose? For our first project, 
out of all the ones we can afford with our initial capital w, we should do the one with the most profit - not only 
does the answer want the maximum capital, but this also opens the door to the most projects for our next decision. 
This logic can be applied at every step - we should always choose the project with the most profit out of the projects 
we can currently afford.

How can we figure out which projects we can afford? We can sort the inputs by capital (ascending), 
and then use a pointer i that stores the index of the most expensive project we can afford. 
Every time we complete a project and add to w, we can move i forward until i is pointing to a project 
that costs more than w.

Great, we know which projects we can afford at each step, but how do we find the maximum? 
Because we only care about the maximum at any given step, this is perfect for a heap. As we increment i, 
put the profit of the projects onto a max heap, and at each step, pop from the heap and add the value to w.

To summarize, greedily choose the most profitable project that you can afford at each step. 
Use a heap to keep track of the most profitable project and add projects to the heap as you gain more capital.

First, let's try to establish why the greedy strategy of picking the most profitable project available at every step is correct.

Of course, the most profitable project will give us the highest gain in money, which is what we are trying to achieve. 
But there are other consequences - when we gain more money, more projects may become available to us.

Let's say we have to choose between two projects, one with profit x and another with profit y, where x < y. 
Is there ever a scenario where we should pick x?

If we pick x, we may gain access to some new projects. But there is no scenario where we wouldn't also gain access 
to those same new projects if we picked y instead, since y > x. In fact, picking y might unlock even more projects 
than picking x.

We can see that at any given step, there is no point in picking a project other than the most profitable one. 
This splits our problem into two parts:
1. Finding which projects are currently available as we gain more money
2. Finding the project with maximum profit at each step

For the first part, if we sort the input according to the project cost, then we can simply iterate over the input 
as we gain more money. As we iterate, if we find a project that is too expensive, 
we know that every project on the right is also too expensive since we sorted.

For the second part, we can use a max heap. As we unlock more projects, we can push to the profit of those projects onto the heap. 
At each step, we can simply pop from the heap to find the most profitable project.

```python
import heapq

class Solution:
    def findMaximizedCapital(self, k: int, w: int, profits: List[int], capital: List[int]) -> int:
        n = len(profits)
        projects = sorted(zip(capital, profits))
        heap = []
        i = 0
        
        for _ in range(k):
            while i < n and projects[i][0] <= w:
                heapq.heappush(heap, -projects[i][1])
                i += 1
            
            if len(heap) == 0:
                # not enough money to do any more projects
                return w
            
            # minus because we stored negative numbers on the heap
            w -= heapq.heappop(heap)
        
        return w
```

This algorithm has a time complexity of O((k+n)⋅logn), where n is the number of projects given. The heap's max size is n, 
which means its operations are logn in the worst case, and we do k + n operations (k pop operations, n push operations). 
The sort at the start also costs O(n⋅logn), but this doesn't change the complexity. 
The space complexity is O(n) due to the heap.

<h3>Example 4: 1481. Least Number of Unique Integers after K Removals</h3>
Given an array of integers arr and an integer k, find the least number of unique integers after removing exactly k elements.

We need to perform k removals - what element is the best to remove? We can improve our answer only if we remove all of an element, so we should greedily remove the element with the lowest frequency at each step.

We can use a hash map to find the frequency of each element. Then we can sort the keys according to their frequencies, and iterate through the keys starting with the least frequent element. At each key, if the frequency is less than or equal to k, we can remove that key and decrease k by the count. We continue this until we run out of removals. The number of keys remaining at the end is the answer.

```python
from collections import Counter

class Solution:
    def findLeastNumOfUniqueInts(self, arr: List[int], k: int) -> int:
        counts = Counter(arr)
        ordered = sorted(counts.values(), reverse=True)
        
        while k:
            val = ordered[-1]
            if val <= k:
                k -= val
                ordered.pop()
            else:
                break

        return len(ordered)
```

In the worst case scenario where all elements are unique, there will be n keys in our hash map, 
where n is the length of the input array, so the sort will cost O(n⋅logn). Each iteration in our while loop runs in O(1), 
and it can also run at most n times, giving a final time complexity of O(n⋅logn). 
The space complexity is O(n) due to the hash map.

<h3>Example 5: 881. Boats to Save People</h3>
You are given an array people where people[i] is the weight of the i-th person. A boat can hold up to two people, 
if their weight combined is less than or equal to limit. What is the fewest number of boats you need to carry everyone? 
Note: no person is heavier than limit.

We want to minimize the number of boats, which means we want to maximize the number of boats that are carrying two people. 
At any given moment, let's say the heaviest person weighs x, and the lightest person weighs y. If x + y > limit, 
that means x cannot pair with anyone and must use their own boat. Therefore, for every heaviest person, 
we should greedily try to pair them with the lightest person.

The intuition behind this: if the lightest person can pair with the heaviest person, why would you choose anyone else 
to pair the lightest person with? Every pairing gives the same value - it will reduce the answer by 1. 
By pairing the heaviest person, you are making it easier in the future to create more pairings.

To keep track of the lightest and heaviest person at any given time, sort the input and use two pointers. 
Have i point to the lightest person and j point to the heaviest person.

Let's try to establish why the greedy strategy of attempting to pair the lightest and heaviest person at each step is optimal.

Let x denote the heaviest person and y denote the lighest person at any given step. There are two possibilities:
1. x + y > limit. There's no way that x can fit with anyone, since y is already the lightest person. 
Therefore they must sit together.
2. x + y <= limit. This implies that y could pair with anyone, since x is already the heaviest person. 
To maximize the efficiency of the boats, if we can pair y with anyone, we should pair them with the heaviest person, 
which is x. This makes the most of the boat and also makes it easier to make future pairings 
since we don't need to worry about x anymore.

Again, this is not a formal proof, but an example of how one could explain their thought process in an interview.

From here, the algorithm is easy to implement using a sort and two pointers.

```python
class Solution:
    def numRescueBoats(self, people: List[int], limit: int) -> int:
        ans = 0
        i = 0
        j = len(people) - 1
        people.sort()
        
        while i <= j:
            if people[i] + people[j] <= limit:
                i += 1

            j -= 1
            ans += 1
        
        return ans
```

Every iteration of the while loop will put the current heaviest person in a boat (that's why we do j-- on every iteration). 
If the lightest person can also come along, then we include them as well (i++).

Like with the two pointer implementations we have already seen, the two pointers part 
of the algorithm runs in n = people.length. However, we needed to sort the input for this algorithm to work, 
which gives us a time complexity of O(n⋅logn). The only extra space used is for the sort, 
which as mentioned previously will depend on the language you're using.

As we can see from the examples, most greedy problems involve sorting the input. 
You could argue that a lot of the problems we have looked at in earlier chapters were greedy problems - especially in the previous chapter (heap). 
Most greedy problems just require some logical reasoning to see that a greedy approach works, 
and then implementation is relatively straightforward. Try these upcoming problems before moving on.
